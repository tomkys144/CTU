#!/usr/bin/python
# -*- coding: utf-8 -*-

import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import norm


def my_parzen(x, x_trn, h):
    """
    p = my_parzen(x, x_trn, h)

    Parzen window density estimation with normal kernel N(0, h^2).

    :param x:       vector of data points where the probability density functions
                    should be evaluated, (n,) np array
    :param x_trn:   training data (m,) np array
    :param h:       kernel bandwidth, python float
    :return p:      estimated p(x|k) evaluated at values given by x (n,) np array
    """

    N = x_trn.size

    kx = np.array([norm.pdf((xi / h) - (x_trn / h)) for xi in x]) / h
    p = 1 / N * np.sum(kx, 1)

    return p


def compute_Lh(itrn, itst, x, h):
    """
    Lh = compute_Lh(itrn, itst, x, h)

    Computes the average log-likelihood over training/test splits generated
    by crossval for a fixed kernel bandwidth h.

    :param itrn:    LIST of (n,) np arrays data splits (indices) generated by crossval()
    :param itst:    LIST of (m,) np arrays data splits (indices) generated by crossval()
    :param x:       input data (n+m,) np array
    :param h:       kernel bandwidth, python float
    :return Lh:     average log-likelihood over training/test splits, python float
    """

    N = len(itst)

    log = []
    for i in range(len(itst)):
        xtst = x[itst[i]]
        xtrn = x[itrn[i]]

        px = my_parzen(xtst, xtrn, h)

        logx = np.log(px)

        log.append(np.sum(logx))

    Lh = 1 / len(itst) * np.sum(log)
    return Lh


def classify_bayes_parzen(x_test, xA, xC, pA, pC, h_bestA, h_bestC):
    """
    labels = classify_bayes_parzen(x_test, xA, xC, pA, pC, h_bestA, h_bestC)

    Classifies data using bayesian classifier with densities estimated by
    Parzen window estimator.

    :param x_test:  data (measurements) to be classified (n,) np array
    :param xA:      training data for Parzen window for class A (n_xA,) np array
    :param xC:      training data for Parzen window for class C (n_xC,) np array
    :param pA:      prior probability for class A, python float
    :param pC:      prior probability for class C, python float
    :param h_bestA: optimal value of the kernel bandwidth, python float
    :param h_bestC: optimal value of the kernel bandwidth, python float
    :return labels: classification labels for x_test (n,) np array
    """

    pxA = my_parzen(x_test, xA, h_bestA)
    pxC = my_parzen(x_test, xC, h_bestC)

    labels = np.where(pA * pxA >= pC * pxC, 0, 1)
    return labels


################################################################################
#####                                                                      #####
#####             Below this line are already prepared methods             #####
#####                                                                      #####
################################################################################


def show_classification(test_images, labels, letters):
    """
    show_classification(test_images, labels, letters)

    create montages of images according to estimated labels

    :param test_images:     np.array (h, w, n)
    :param labels:          labels for input images np.array (n,)
    :param letters:         string with letters, e.g. 'CN'
    """

    def montage(images, colormap='gray'):
        """
        Show images in grid.

        :param images:      np.array (h, w, n)
        :param colormap:    numpy colormap
        """
        h, w, count = np.shape(images)
        h_sq = np.int(np.ceil(np.sqrt(count)))
        w_sq = h_sq
        im_matrix = np.zeros((h_sq * h, w_sq * w))

        image_id = 0
        for j in range(h_sq):
            for k in range(w_sq):
                if image_id >= count:
                    break
                slice_w = j * h
                slice_h = k * w
                im_matrix[slice_h:slice_h + w, slice_w:slice_w + h] = images[:, :, image_id]
                image_id += 1
        plt.imshow(im_matrix, cmap=colormap)
        plt.axis('off')
        return im_matrix

    for i in range(len(letters)):
        imgs = test_images[:, :, labels == i]
        subfig = plt.subplot(1, len(letters), i + 1)
        montage(imgs)
        plt.title(letters[i])


def crossval(num_data, num_folds):
    """
    itrn, itst = crossval(num_data, num_folds)

    Partitions data for cross-validation.

    This function randomly partitions data into the training
    and testing parts. The number of partitioning is determined
    by the num_folds. If num_folds==1 then makes only one random
    partitioning of data into training and testing in ratio 50:50.

    :param num_data:    number of data (scalar, integer)
    :param num_folds:   number of folders (scalar, integer)
    :return itrn:       itrn - LIST of training folds, itst - LIST of testing folds
                            itrn[i] indices of training data of i-th folder (n,) np array
                            itst[i] indices of testing data of i-th folder (n,) np array
    """
    if num_folds < 2:
        print("Minimal number of folds set to 2.")
        num_folds = 2

    inx = np.random.permutation(num_data)

    itrn = []
    itst = []

    num_column = np.int32(np.ceil(np.float64(num_data) / num_folds))

    for idx in range(num_folds):
        tst_idx = range((idx * num_column), np.min([num_data, ((idx + 1) * num_column)]))
        trn_idx = [i for i in list(range(num_data)) if i not in tst_idx]
        itst.append(inx[tst_idx])
        itrn.append(inx[trn_idx])
    return itrn, itst


def compute_measurement_lr_cont(imgs):
    """
    x = compute_measurement_lr_cont(imgs)

    Compute measurement on images, subtract sum of right half from sum of
    left half.

    :param imgs:    set of images, (h, w, n)
    :return:        measurements, (n, )
    """
    assert len(imgs.shape) == 3

    width = imgs.shape[1]
    sum_rows = np.sum(imgs, dtype=np.float64, axis=0)

    x = np.sum(sum_rows[0:int(width / 2), :], axis=0) - np.sum(sum_rows[int(width / 2):, :], axis=0)

    assert x.shape == (imgs.shape[2],)
    return x


def main():
    data = np.load("data_33rpz_parzen.npz", allow_pickle=True)
    tst = data["tst"].item()
    trn = data["trn"].item()

    x = compute_measurement_lr_cont(trn['images'])

    # splitting the trainning data into classes
    idxs = np.squeeze(trn['labels'])
    xA = x[idxs == 0]
    xC = x[idxs == 1]

    x_range = np.arange(np.min(xA), np.max(xA), 100)
    h = [100., 500., 1000., 2000.]

    y = np.zeros([len(h), x_range.size], np.float64)
    for i in range(len(h)):
        y[i, :] = my_parzen(x_range, xA, h[i])

    h_range = np.linspace(100, 1000, 19)
    num_folds = 10

    np.random.seed(42)  # to get the same example outputs

    num_data = xA.size
    itrn, itst = crossval(num_data, num_folds)

    Lh = np.array([compute_Lh(itrn, itst, xA, h_i) for h_i in h_range])

    print(Lh)


if __name__ == "__main__":
    main()
